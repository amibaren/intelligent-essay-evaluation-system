#!/usr/bin/env python3
"""
OxyGentå·¥ä½œæµç¨‹ç®¡ç†å™¨

é‡æ–°è®¾è®¡æ™ºèƒ½ä½“é—´çš„å·¥ä½œæµç¨‹ä¾èµ–å…³ç³»
å»ºç«‹æ¸…æ™°çš„çº¿æ€§æµç¨‹ï¼šInput â†’ Template â†’ Analysis â†’ Report
ä¿®å¤MasterAgentè·³è¿‡æ­¥éª¤çš„é—®é¢˜
"""

import asyncio
import time
from enum import Enum
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from loguru import logger

from oxygent import OxyRequest, OxyResponse, OxyState


class WorkflowStep(Enum):
    """å·¥ä½œæµç¨‹æ­¥éª¤"""
    INPUT_VALIDATION = "input_validation"
    TEMPLATE_GENERATION = "template_generation"
    PARALLEL_ANALYSIS = "parallel_analysis"
    REPORT_GENERATION = "report_generation"
    OUTPUT_FORMATTING = "output_formatting"


class StepStatus(Enum):
    """æ­¥éª¤çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class WorkflowContext:
    """å·¥ä½œæµç¨‹ä¸Šä¸‹æ–‡"""
    session_id: str
    request_type: str  # essay_evaluation, teaching_consultation
    input_data: Dict[str, Any]
    current_step: WorkflowStep
    step_results: Dict[WorkflowStep, Any]
    step_status: Dict[WorkflowStep, StepStatus]
    start_time: float
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "session_id": self.session_id,
            "request_type": self.request_type,
            "input_data": self.input_data,
            "current_step": self.current_step.value,
            "step_results": {step.value: result for step, result in self.step_results.items()},
            "step_status": {step.value: status.value for step, status in self.step_status.items()},
            "start_time": self.start_time,
            "metadata": self.metadata
        }


class WorkflowManager:
    """å·¥ä½œæµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_workflows: Dict[str, WorkflowContext] = {}
        self.workflow_history: List[Dict[str, Any]] = []
        self.step_handlers: Dict[WorkflowStep, Callable] = {}
        
        # å®šä¹‰æ ‡å‡†å·¥ä½œæµç¨‹
        self.standard_workflow = [
            WorkflowStep.INPUT_VALIDATION,
            WorkflowStep.TEMPLATE_GENERATION,
            WorkflowStep.PARALLEL_ANALYSIS,
            WorkflowStep.REPORT_GENERATION,
            WorkflowStep.OUTPUT_FORMATTING
        ]
        
        # åˆå§‹åŒ–æ­¥éª¤å¤„ç†å™¨
        self._setup_step_handlers()
    
    def _setup_step_handlers(self):
        """è®¾ç½®æ­¥éª¤å¤„ç†å™¨"""
        self.step_handlers = {
            WorkflowStep.INPUT_VALIDATION: self._handle_input_validation,
            WorkflowStep.TEMPLATE_GENERATION: self._handle_template_generation,
            WorkflowStep.PARALLEL_ANALYSIS: self._handle_parallel_analysis,
            WorkflowStep.REPORT_GENERATION: self._handle_report_generation,
            WorkflowStep.OUTPUT_FORMATTING: self._handle_output_formatting
        }
    
    async def start_workflow(self, 
                           session_id: str, 
                           request_type: str, 
                           input_data: Dict[str, Any]) -> WorkflowContext:
        """å¯åŠ¨æ–°çš„å·¥ä½œæµç¨‹"""
        # åˆ›å»ºå·¥ä½œæµç¨‹ä¸Šä¸‹æ–‡
        context = WorkflowContext(
            session_id=session_id,
            request_type=request_type,
            input_data=input_data,
            current_step=WorkflowStep.INPUT_VALIDATION,
            step_results={},
            step_status={step: StepStatus.PENDING for step in self.standard_workflow},
            start_time=time.time(),
            metadata={}
        )
        
        self.active_workflows[session_id] = context
        logger.info(f"ğŸš€ å¯åŠ¨å·¥ä½œæµç¨‹: {session_id} ({request_type})")
        
        return context
    
    async def execute_workflow(self, session_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµç¨‹"""
        if session_id not in self.active_workflows:
            raise ValueError(f"æœªæ‰¾åˆ°å·¥ä½œæµç¨‹: {session_id}")
        
        context = self.active_workflows[session_id]
        
        try:
            # æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ­¥éª¤
            for step in self.standard_workflow:
                if context.step_status[step] == StepStatus.COMPLETED:
                    logger.debug(f"â­ï¸ è·³è¿‡å·²å®Œæˆæ­¥éª¤: {step.value}")
                    continue
                
                await self._execute_step(context, step)
                
                # æ£€æŸ¥æ˜¯å¦å¤±è´¥
                if context.step_status[step] == StepStatus.FAILED:
                    logger.error(f"âŒ å·¥ä½œæµç¨‹åœ¨æ­¥éª¤ {step.value} å¤±è´¥")
                    break
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = self._generate_final_result(context)
            
            # ç§»åŠ¨åˆ°å†å²è®°å½•
            self._archive_workflow(context)
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {session_id}: {e}")
            context.step_status[context.current_step] = StepStatus.FAILED
            raise
    
    async def _execute_step(self, context: WorkflowContext, step: WorkflowStep):
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        logger.info(f"ğŸ“‹ æ‰§è¡Œæ­¥éª¤: {step.value} (ä¼šè¯: {context.session_id})")
        
        context.current_step = step
        context.step_status[step] = StepStatus.RUNNING
        
        try:
            # è°ƒç”¨å¯¹åº”çš„å¤„ç†å™¨
            handler = self.step_handlers.get(step)
            if handler:
                result = await handler(context)
                context.step_results[step] = result
                context.step_status[step] = StepStatus.COMPLETED
                logger.info(f"âœ… æ­¥éª¤å®Œæˆ: {step.value}")
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ­¥éª¤å¤„ç†å™¨: {step.value}")
                context.step_status[step] = StepStatus.SKIPPED
                
        except Exception as e:
            logger.error(f"âŒ æ­¥éª¤æ‰§è¡Œå¤±è´¥: {step.value}: {e}")
            context.step_status[step] = StepStatus.FAILED
            raise
    
    async def _handle_input_validation(self, context: WorkflowContext) -> Dict[str, Any]:
        """å¤„ç†è¾“å…¥éªŒè¯æ­¥éª¤"""
        input_data = context.input_data
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = {
            'essay_evaluation': ['essay_content', 'grade_level'],
            'teaching_consultation': ['requirements']
        }
        
        required = required_fields.get(context.request_type, [])
        missing_fields = [field for field in required if field not in input_data]
        
        if missing_fields:
            raise ValueError(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
        
        # å¤„ç†å’Œæ¸…ç†è¾“å…¥æ•°æ®
        cleaned_data = {
            'essay_content': input_data.get('essay_content', '').strip(),
            'grade_level': input_data.get('grade_level', 'grade_3'),
            'essay_type': input_data.get('essay_type', 'narrative'),
            'teaching_focus': input_data.get('teaching_focus', ''),
            'student_info': input_data.get('student_info', {}),
            'requirements': input_data.get('requirements', '')
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        context.metadata.update({
            'word_count': len(cleaned_data['essay_content']),
            'estimated_complexity': self._estimate_complexity(cleaned_data),
            'validation_time': time.time()
        })
        
        logger.info(f"âœ… è¾“å…¥éªŒè¯å®Œæˆï¼Œå­—æ•°: {context.metadata['word_count']}")
        return cleaned_data
    
    async def _handle_template_generation(self, context: WorkflowContext) -> Dict[str, Any]:
        """å¤„ç†æ¨¡æ¿ç”Ÿæˆæ­¥éª¤"""
        validated_data = context.step_results[WorkflowStep.INPUT_VALIDATION]
        
        # æ„å»ºå¯¹ instructional_designer çš„è°ƒç”¨
        template_request = {
            'agent_name': 'instructional_designer',
            'arguments': {
                'essay_content': validated_data['essay_content'],
                'grade_level': validated_data['grade_level'], 
                'essay_type': validated_data['essay_type'],
                'teaching_focus': validated_data['teaching_focus'],
                'query_type': context.request_type
            }
        }
        
        logger.info("ğŸ“ è°ƒç”¨æ•™å­¦æ¨¡æ¿è®¾è®¡å¸ˆ...")
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ™ºèƒ½ä½“
        # ä¸ºäº†æ¼”ç¤ºï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        template_result = {
            'evaluation_template': {
                'content_criteria': ['ä¸»é¢˜æ˜ç¡®', 'ç»“æ„æ¸…æ™°', 'è¯­è¨€æµç•…'],
                'language_criteria': ['è¯æ±‡ä¸°å¯Œ', 'å¥å¼å¤šæ ·', 'ä¿®è¾æ°å½“'],
                'structure_criteria': ['å¼€å¤´å¸å¼•äºº', 'è¿‡æ¸¡è‡ªç„¶', 'ç»“å°¾æœ‰åŠ›'],
                'grade_specific_focus': validated_data['grade_level']
            },
            'template_metadata': {
                'generation_time': time.time(),
                'complexity_level': context.metadata.get('estimated_complexity', 'medium')
            }
        }
        
        logger.info("âœ… æ•™å­¦æ¨¡æ¿ç”Ÿæˆå®Œæˆ")
        return template_result
    
    async def _handle_parallel_analysis(self, context: WorkflowContext) -> Dict[str, Any]:
        """å¤„ç†å¹¶è¡Œåˆ†ææ­¥éª¤"""
        validated_data = context.step_results[WorkflowStep.INPUT_VALIDATION]
        template_data = context.step_results[WorkflowStep.TEMPLATE_GENERATION]
        
        # å‡†å¤‡å¹¶è¡Œåˆ†æä»»åŠ¡
        analysis_tasks = [
            self._call_text_analyst(validated_data, template_data),
            self._call_praiser(validated_data),
            self._call_guide(validated_data)
        ]
        
        logger.info("ğŸ”„ å¼€å§‹å¹¶è¡Œåˆ†æ...")
        
        # æ‰§è¡Œå¹¶è¡Œåˆ†æ
        try:
            results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            analysis_result = {
                'text_analysis': results[0] if not isinstance(results[0], Exception) else None,
                'praise_feedback': results[1] if not isinstance(results[1], Exception) else None,
                'guidance_suggestions': results[2] if not isinstance(results[2], Exception) else None,
                'analysis_metadata': {
                    'parallel_execution': True,
                    'completion_time': time.time(),
                    'success_count': sum(1 for r in results if not isinstance(r, Exception))
                }
            }
            
            logger.info(f"âœ… å¹¶è¡Œåˆ†æå®Œæˆï¼ŒæˆåŠŸ: {analysis_result['analysis_metadata']['success_count']}/3")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ å¹¶è¡Œåˆ†æå¤±è´¥: {e}")
            raise
    
    async def _handle_report_generation(self, context: WorkflowContext) -> Dict[str, Any]:
        """å¤„ç†æŠ¥å‘Šç”Ÿæˆæ­¥éª¤"""
        validated_data = context.step_results[WorkflowStep.INPUT_VALIDATION]
        template_data = context.step_results[WorkflowStep.TEMPLATE_GENERATION]
        analysis_data = context.step_results[WorkflowStep.PARALLEL_ANALYSIS]
        
        # æ„å»ºå¯¹ reporter çš„è°ƒç”¨
        report_request = {
            'agent_name': 'reporter',
            'arguments': {
                'essay_content': validated_data['essay_content'],
                'evaluation_template': template_data['evaluation_template'],
                'text_analysis': analysis_data['text_analysis'],
                'praise_feedback': analysis_data['praise_feedback'],
                'guidance_suggestions': analysis_data['guidance_suggestions'],
                'student_info': validated_data['student_info']
            }
        }
        
        logger.info("ğŸ“Š è°ƒç”¨æŠ¥å‘Šæ±‡æ€»å¸ˆ...")
        
        # æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ
        report_result = {
            'comprehensive_report': {
                'overall_score': 85,
                'strengths': ['ä¸»é¢˜æ˜ç¡®', 'è¯­è¨€ç”ŸåŠ¨'],
                'improvements': ['ç»“æ„å¯ä»¥æ›´æ¸…æ™°', 'ç»“å°¾éœ€è¦åŠ å¼º'],
                'detailed_feedback': 'è¿™æ˜¯ä¸€ç¯‡å¾ˆå¥½çš„ä½œæ–‡...',
                'next_steps': ['å¤šç»ƒä¹ å¼€å¤´ç»“å°¾', 'å¢åŠ æå†™ç»†èŠ‚']
            },
            'report_metadata': {
                'generation_time': time.time(),
                'template_used': template_data['evaluation_template'],
                'analysis_sources': list(analysis_data.keys())
            }
        }
        
        logger.info("âœ… ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return report_result
    
    async def _handle_output_formatting(self, context: WorkflowContext) -> Dict[str, Any]:
        """å¤„ç†è¾“å‡ºæ ¼å¼åŒ–æ­¥éª¤"""
        report_data = context.step_results[WorkflowStep.REPORT_GENERATION]
        
        # æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º
        formatted_output = {
            'evaluation_result': report_data['comprehensive_report'],
            'process_summary': {
                'total_time': time.time() - context.start_time,
                'steps_completed': [
                    step.value for step, status in context.step_status.items() 
                    if status == StepStatus.COMPLETED
                ],
                'workflow_type': context.request_type
            },
            'metadata': context.metadata
        }
        
        logger.info("âœ… è¾“å‡ºæ ¼å¼åŒ–å®Œæˆ")
        return formatted_output
    
    async def _call_text_analyst(self, validated_data: Dict, template_data: Dict) -> Dict[str, Any]:
        """è°ƒç”¨æ–‡æœ¬åˆ†æå¸ˆ"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹ŸAPIè°ƒç”¨
        return {
            'analysis_type': 'text_analysis',
            'findings': ['è¯­è¨€è¡¨è¾¾æ¸…æ™°', 'é€»è¾‘ç»“æ„å®Œæ•´'],
            'technical_details': {'word_count': len(validated_data['essay_content'])}
        }
    
    async def _call_praiser(self, validated_data: Dict) -> Dict[str, Any]:
        """è°ƒç”¨èµç¾é¼“åŠ±å¸ˆ"""
        await asyncio.sleep(0.3)  # æ¨¡æ‹ŸAPIè°ƒç”¨
        return {
            'analysis_type': 'praise_feedback',
            'encouragements': ['ç”¨è¯å¾ˆç”ŸåŠ¨', 'æƒ³è±¡åŠ›ä¸°å¯Œ'],
            'motivation': 'ç»§ç»­ä¿æŒè¿™ç§åˆ›ä½œçƒ­æƒ…ï¼'
        }
    
    async def _call_guide(self, validated_data: Dict) -> Dict[str, Any]:
        """è°ƒç”¨å¯å‘å¼•å¯¼å¸ˆ"""
        await asyncio.sleep(0.4)  # æ¨¡æ‹ŸAPIè°ƒç”¨
        return {
            'analysis_type': 'guidance_suggestions',
            'questions': ['å¯ä»¥æ·»åŠ æ›´å¤šç»†èŠ‚æå†™å—ï¼Ÿ', 'ç»“å°¾æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿ'],
            'suggestions': ['å°è¯•ä½¿ç”¨æ¯”å–»å¥', 'è€ƒè™‘æ·»åŠ äººç‰©å¯¹è¯']
        }
    
    def _estimate_complexity(self, data: Dict[str, Any]) -> str:
        """ä¼°ç®—ä»»åŠ¡å¤æ‚åº¦"""
        essay_length = len(data.get('essay_content', ''))
        
        if essay_length < 200:
            return 'low'
        elif essay_length < 500:
            return 'medium'
        else:
            return 'high'
    
    def _generate_final_result(self, context: WorkflowContext) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»“æœ"""
        if WorkflowStep.OUTPUT_FORMATTING in context.step_results:
            return context.step_results[WorkflowStep.OUTPUT_FORMATTING]
        
        # å¦‚æœæ ¼å¼åŒ–æ­¥éª¤å¤±è´¥ï¼Œè¿”å›åŸºç¡€ç»“æœ
        return {
            'session_id': context.session_id,
            'status': 'partial_completion',
            'completed_steps': [
                step.value for step, status in context.step_status.items()
                if status == StepStatus.COMPLETED
            ],
            'available_results': {
                step.value: result for step, result in context.step_results.items()
            }
        }
    
    def _archive_workflow(self, context: WorkflowContext):
        """å½’æ¡£å·¥ä½œæµç¨‹"""
        # ç§»åŠ¨åˆ°å†å²è®°å½•
        self.workflow_history.append(context.to_dict())
        
        # ä»æ´»è·ƒå·¥ä½œæµç¨‹ä¸­ç§»é™¤
        if context.session_id in self.active_workflows:
            del self.active_workflows[context.session_id]
        
        # ä¿ç•™æœ€è¿‘100ä¸ªå†å²è®°å½•
        if len(self.workflow_history) > 100:
            self.workflow_history = self.workflow_history[-100:]
        
        logger.info(f"ğŸ“ å·¥ä½œæµç¨‹å·²å½’æ¡£: {context.session_id}")
    
    def get_workflow_status(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµç¨‹çŠ¶æ€"""
        if session_id in self.active_workflows:
            context = self.active_workflows[session_id]
            return {
                'session_id': session_id,
                'current_step': context.current_step.value,
                'progress': self._calculate_progress(context),
                'step_status': {step.value: status.value for step, status in context.step_status.items()},
                'elapsed_time': time.time() - context.start_time
            }
        return None
    
    def _calculate_progress(self, context: WorkflowContext) -> float:
        """è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”"""
        completed = sum(1 for status in context.step_status.values() if status == StepStatus.COMPLETED)
        total = len(self.standard_workflow)
        return (completed / total) * 100
    
    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            'active_workflows': len(self.active_workflows),
            'completed_workflows': len(self.workflow_history),
            'step_handlers': len(self.step_handlers),
            'standard_workflow_steps': [step.value for step in self.standard_workflow]
        }


# å…¨å±€å·¥ä½œæµç¨‹ç®¡ç†å™¨å®ä¾‹
workflow_manager = WorkflowManager()


def get_workflow_manager() -> WorkflowManager:
    """è·å–å…¨å±€å·¥ä½œæµç¨‹ç®¡ç†å™¨"""
    return workflow_manager


async def execute_essay_evaluation_workflow(session_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œä½œæ–‡è¯„ä»·å·¥ä½œæµç¨‹"""
    wm = get_workflow_manager()
    
    # å¯åŠ¨å·¥ä½œæµç¨‹
    context = await wm.start_workflow(session_id, 'essay_evaluation', input_data)
    
    # æ‰§è¡Œå·¥ä½œæµç¨‹
    result = await wm.execute_workflow(session_id)
    
    return result


async def execute_teaching_consultation_workflow(session_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæ•™å­¦å’¨è¯¢å·¥ä½œæµç¨‹"""
    wm = get_workflow_manager()
    
    # å¯åŠ¨å·¥ä½œæµç¨‹  
    context = await wm.start_workflow(session_id, 'teaching_consultation', input_data)
    
    # æ‰§è¡Œå·¥ä½œæµç¨‹
    result = await wm.execute_workflow(session_id)
    
    return result


if __name__ == "__main__":
    # æµ‹è¯•å·¥ä½œæµç¨‹ç®¡ç†å™¨
    print("ğŸ§ª æµ‹è¯•å·¥ä½œæµç¨‹ç®¡ç†å™¨")
    
    async def test_workflow():
        wm = get_workflow_manager()
        
        # æµ‹è¯•ä½œæ–‡è¯„ä»·å·¥ä½œæµç¨‹
        test_input = {
            'essay_content': 'æ˜¥å¤©æ¥äº†ï¼ŒèŠ±å¼€äº†ï¼Œé¸Ÿå„¿åœ¨å”±æ­Œã€‚æˆ‘å–œæ¬¢æ˜¥å¤©çš„ç¾ä¸½æ™¯è‰²ã€‚',
            'grade_level': 'grade_3',
            'essay_type': 'descriptive',
            'student_info': {'name': 'å°æ˜', 'age': 9}
        }
        
        session_id = f"test_session_{int(time.time())}"
        
        print(f"\nğŸ“‹ å¼€å§‹æµ‹è¯•å·¥ä½œæµç¨‹: {session_id}")
        
        try:
            result = await execute_essay_evaluation_workflow(session_id, test_input)
            print(f"âœ… å·¥ä½œæµç¨‹å®Œæˆ")
            print(f"ç»“æœæ‘˜è¦: {result.get('process_summary', {})}")
            
            # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
            stats = wm.get_system_stats()
            print(f"ç³»ç»Ÿç»Ÿè®¡: {stats}")
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµç¨‹å¤±è´¥: {e}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_workflow())
    print("\nâœ… å·¥ä½œæµç¨‹ç®¡ç†å™¨æµ‹è¯•å®Œæˆ")